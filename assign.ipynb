{
 "cells": [
  {
   "cell_type": "code",
   "id": "21291d2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:45:57.597565Z",
     "start_time": "2025-05-15T15:45:57.588123Z"
    }
   },
   "source": [
    "# First cell: Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "\n",
    "# Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "b82ac0ab",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing, Scaling, and Encoding\n",
    "\n",
    "We first load the dataset, check for missing values or irregularities, and apply scaling where needed. \n",
    "Since the dataset is numerical and clean, no encoding is needed. Only scaling is performed where necessary \n",
    "(for example, SVM benefits from feature scaling).\n",
    "\n",
    "We assume the target variable is `conflict` (0 or 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "6b573fd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T16:15:08.760375Z",
     "start_time": "2025-05-15T16:15:08.645286Z"
    }
   },
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"MergeConflictsDataset.csv\")  # Replace with your actual CSV file name\n",
    "\n",
    "# Drop identifiers and keep only relevant features\n",
    "df = df.drop(columns=[\"commit\", \"parent1\", \"parent2\", \"ancestor\"])\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Feature and target separation\n",
    "X = df.drop(\"conflict\", axis=1)\n",
    "y = df[\"conflict\"]\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is pr              0\n",
      "added lines        0\n",
      "deleted lines      0\n",
      "devs parent1       0\n",
      "devs parent2       0\n",
      "time               0\n",
      "nr files           0\n",
      "added files        0\n",
      "deleted files      0\n",
      "renamed files      0\n",
      "copied files       0\n",
      "modified files     0\n",
      "nr commits1        0\n",
      "nr commits2        0\n",
      "density1           0\n",
      "density2           0\n",
      "fix                0\n",
      "bug                0\n",
      "feature            0\n",
      "improve            0\n",
      "document           0\n",
      "refactor           0\n",
      "update             0\n",
      "add                0\n",
      "remove             0\n",
      "use                0\n",
      "delete             0\n",
      "change             0\n",
      "messages_min       0\n",
      "messages_max       0\n",
      "messages_mean      0\n",
      "messages_median    0\n",
      "conflict           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "533761bc",
   "metadata": {},
   "source": [
    "## 2. Train/Test Split (with Stratification)\n",
    "\n",
    "To ensure balanced class distribution in training and test sets, we use stratified splitting. This helps in\n",
    "cases where classes are imbalanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "63d865ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:48:47.657018Z",
     "start_time": "2025-05-15T15:48:47.580903Z"
    }
   },
   "source": [
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale the features for models like SVM\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "print(X_train.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21578, 32)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "61ceca43",
   "metadata": {},
   "source": [
    "## 3. Performance Metric Selection\n",
    "\n",
    "We evaluate using accuracy, precision, recall, F1-score, and ROC-AUC. Since this is a binary classification\n",
    "task, ROC-AUC is particularly useful to evaluate how well the model separates the two classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d0cf5b",
   "metadata": {},
   "source": [
    "## 4. Feature Selection\n",
    "\n",
    "We can use feature importance from Decision Trees to identify top features. This helps build interpretable\n",
    "and slim models, especially useful when performance is close to the full model.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "1fb262d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:45:58.064784Z",
     "start_time": "2025-05-15T15:45:57.938484Z"
    }
   },
   "source": [
    "# Train a basic decision tree\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Get feature importances (using original column names)\n",
    "importances = pd.Series(tree.feature_importances_, index=X.columns)\n",
    "top_features = importances.sort_values(ascending=False).head(10)\n",
    "print(\"Top 10 important features:\")\n",
    "print(top_features)\n",
    "\n",
    "# Convert scaled arrays back to DataFrames for column name access\n",
    "X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "# Slice by top features\n",
    "top_feature_names = top_features.index.tolist()\n",
    "X_train_slim = X_train_df[top_feature_names].values\n",
    "X_test_slim = X_test_df[top_feature_names].values"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 important features:\n",
      "nr files           0.347054\n",
      "is pr              0.161846\n",
      "nr commits2        0.041396\n",
      "messages_min       0.035067\n",
      "messages_max       0.033217\n",
      "deleted lines      0.030806\n",
      "messages_median    0.028409\n",
      "messages_mean      0.027895\n",
      "time               0.027664\n",
      "add                0.026304\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "c749cba4",
   "metadata": {},
   "source": [
    "## 5. Model Selection, Evaluation, Optimization\n",
    "\n",
    "We evaluate three models: Decision Tree, SVM (or Naive Bayes), and an ensemble method (Random Forest or AdaBoost).\n",
    "For each, we perform hyperparameter tuning using GridSearchCV and avoid overfitting by using validation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "09a88254",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:45:59.551478Z",
     "start_time": "2025-05-15T15:45:58.100029Z"
    }
   },
   "source": [
    "tree_params = {'max_depth': [3, 5, 10, None]}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(random_state=42), tree_params, cv=5)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "y_pred_tree = grid_tree.predict(X_test)\n",
    "\n",
    "print(\"Best Tree Params:\", grid_tree.best_params_)\n",
    "print(classification_report(y_test, y_pred_tree))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tree Params: {'max_depth': 5}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      5101\n",
      "           1       0.67      0.61      0.64       294\n",
      "\n",
      "    accuracy                           0.96      5395\n",
      "   macro avg       0.82      0.80      0.81      5395\n",
      "weighted avg       0.96      0.96      0.96      5395\n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "4964bd68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:45:59.730419500Z",
     "start_time": "2025-05-15T14:09:42.032232Z"
    }
   },
   "source": [
    "svm_params = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "grid_svm = GridSearchCV(SVC(probability=True), svm_params, cv=5)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "\n",
    "print(\"Best SVM Params:\", grid_svm.best_params_)\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Params: {'C': 1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      5101\n",
      "           1       0.76      0.31      0.44       294\n",
      "\n",
      "    accuracy                           0.96      5395\n",
      "   macro avg       0.86      0.65      0.71      5395\n",
      "weighted avg       0.95      0.96      0.95      5395\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "f392bcac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:45:59.733931200Z",
     "start_time": "2025-05-15T14:16:26.329080Z"
    }
   },
   "source": [
    "rf_params = {'n_estimators': [50, 100], 'max_depth': [5, 10, None]}\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=5)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "y_pred_rf = grid_rf.predict(X_test)\n",
    "\n",
    "print(\"Best RF Params:\", grid_rf.best_params_)\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'max_depth': None, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5101\n",
      "           1       0.75      0.56      0.64       294\n",
      "\n",
      "    accuracy                           0.97      5395\n",
      "   macro avg       0.86      0.78      0.81      5395\n",
      "weighted avg       0.96      0.97      0.96      5395\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "9c91c26b",
   "metadata": {},
   "source": [
    "## 6. New Feature Proposals\n",
    "\n",
    "We propose the following derived features:\n",
    "- **commit_activity_diff** = abs(nr_commits1 - nr_commits2)\n",
    "- **keyword_sum** = sum of all keyword-related counts (fix, bug, feature, ...)\n",
    "- **message_length_range** = messages_max - messages_min\n",
    "\n",
    "We re-train the best model with these features added to the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "76d3866e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T15:45:59.749568400Z",
     "start_time": "2025-05-15T14:16:51.709766Z"
    }
   },
   "source": [
    "df[\"commit_activity_diff\"] = abs(df[\"nr commits1\"] - df[\"nr commits2\"])\n",
    "df[\"keyword_sum\"] = df[[\"fix\",\"bug\",\"feature\",\"improve\",\"document\",\"refactor\",\"update\",\"add\",\"remove\",\"use\",\"delete\",\"change\"]].sum(axis=1)\n",
    "df[\"message_length_range\"] = df[\"messages_max\"] - df[\"messages_min\"]\n",
    "\n",
    "# Add to X and re-scale\n",
    "X_new = df.drop(\"conflict\", axis=1)\n",
    "X_new_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(\n",
    "    X_new_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Retrain best model (e.g., Random Forest)\n",
    "grid_rf.fit(X_train_new, y_train_new)\n",
    "y_pred_new = grid_rf.predict(X_test_new)\n",
    "\n",
    "print(\"Performance with new features:\")\n",
    "print(classification_report(y_test_new, y_pred_new))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with new features:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5101\n",
      "           1       0.76      0.56      0.65       294\n",
      "\n",
      "    accuracy                           0.97      5395\n",
      "   macro avg       0.87      0.78      0.82      5395\n",
      "weighted avg       0.96      0.97      0.96      5395\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
